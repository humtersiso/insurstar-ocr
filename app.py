import os
import datetime
import threading
from flask import Flask, request, jsonify, render_template, send_file, send_from_directory
from flask_cors import CORS
from werkzeug.utils import secure_filename
import tempfile
import shutil
import json
import time

from gemini_ocr_processor import GeminiOCRProcessor
from data_processor import DataProcessor
from image_processing import ImageProcessing
from word_template_processor import WordTemplateProcessorPure
from auto_cleanup_manager import start_auto_cleanup, stop_auto_cleanup, add_session_file, get_cleanup_manager

app = Flask(__name__)
CORS(app)

# è¨­å®š
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB
app.config['UPLOAD_FOLDER'] = 'uploads'
app.config['OUTPUT_FOLDER'] = 'property_reports'
app.config['ALLOWED_EXTENSIONS'] = {'png', 'jpg', 'jpeg', 'pdf', 'tiff', 'bmp'}

# å»ºç«‹å¿…è¦çš„è³‡æ–™å¤¾
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)
os.makedirs(app.config['OUTPUT_FOLDER'], exist_ok=True)

# å»ºç«‹æš«å­˜åœ–ç‰‡è³‡æ–™å¤¾
TEMP_PREVIEW_FOLDER = os.path.join(os.path.dirname(__file__), 'temp_images')
os.makedirs(TEMP_PREVIEW_FOLDER, exist_ok=True)

# å•Ÿå‹•æ™‚ä¸æ¸…ç† temp_images è³‡æ–™å¤¾ï¼Œä¿ç•™é è¦½åœ–ç‰‡
# def cleanup_temp_previews_on_start(folder):
#     for filename in os.listdir(folder):
#         file_path = os.path.join(folder, filename)
#         if os.path.isfile(file_path):
#             try:
#                 os.remove(file_path)
#             except Exception as e:
#                 print(f"åˆªé™¤æš«å­˜æª”æ¡ˆå¤±æ•—: {file_path} - {e}")

# cleanup_temp_previews_on_start(TEMP_PREVIEW_FOLDER)

# åˆå§‹åŒ–è™•ç†å™¨
ocr_processor = GeminiOCRProcessor()  # ä½¿ç”¨ Gemini OCR
data_processor = DataProcessor()
image_processor = ImageProcessing

# åˆå§‹åŒ– Word æ¨¡æ¿è™•ç†å™¨
try:
    word_template_processor = WordTemplateProcessorPure()  # Word æ¨¡æ¿è™•ç†å™¨
    print("âœ… Word æ¨¡æ¿è™•ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
except Exception as e:
    print(f"âŒ Word æ¨¡æ¿è™•ç†å™¨åˆå§‹åŒ–å¤±æ•—: {str(e)}")
    word_template_processor = None

# å•Ÿå‹•è‡ªå‹•æ¸…ç†ç®¡ç†å™¨
try:
    start_auto_cleanup()
    print("âœ… è‡ªå‹•æ¸…ç†ç®¡ç†å™¨å·²å•Ÿå‹•")
except Exception as e:
    print(f"âŒ è‡ªå‹•æ¸…ç†ç®¡ç†å™¨å•Ÿå‹•å¤±æ•—: {str(e)}")

def allowed_file(filename):
    """æª¢æŸ¥æª”æ¡ˆæ ¼å¼æ˜¯å¦å…è¨±"""
    return '.' in filename and \
           filename.rsplit('.', 1)[1].lower() in app.config['ALLOWED_EXTENSIONS']

def cleanup_temp_files(file_paths):
    """æ¸…ç†æš«å­˜æª”æ¡ˆ"""
    for file_path in file_paths:
        try:
            if os.path.exists(file_path):
                os.remove(file_path)
        except Exception as e:
            print(f"æ¸…ç†æª”æ¡ˆéŒ¯èª¤: {str(e)}")

@app.route('/')
def index():
    """é¦–é """
    return render_template('index.html')

@app.route('/upload', methods=['POST'])
def upload_file():
    """è™•ç†æª”æ¡ˆä¸Šå‚³å’ŒOCRè¾¨è­˜"""
    try:
        # æª¢æŸ¥æ˜¯å¦æœ‰æª”æ¡ˆ
        if 'file' not in request.files:
            return jsonify({'error': 'æ²’æœ‰é¸æ“‡æª”æ¡ˆ'}), 400
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({'error': 'æ²’æœ‰é¸æ“‡æª”æ¡ˆ'}), 400
        
        if not allowed_file(file.filename):
            return jsonify({'error': 'ä¸æ”¯æ´çš„æª”æ¡ˆæ ¼å¼'}), 400
        
        # ç”Ÿæˆå”¯ä¸€æª”æ¡ˆå
        filename = secure_filename(file.filename or 'unknown')
        file_ext = filename.rsplit('.', 1)[1].lower()
        upload_path = os.path.join(app.config['UPLOAD_FOLDER'], f"{filename}.{file_ext}")
        
        # ä¿å­˜ä¸Šå‚³çš„æª”æ¡ˆ
        file.save(upload_path)
        
        # è¨»å†Šæœƒè©±æª”æ¡ˆï¼ˆç”¨æ–¼è‡ªå‹•æ¸…ç†ï¼‰
        add_session_file(upload_path)

        # å¦‚æœæ˜¯ PDFï¼Œå…ˆè½‰æˆåœ–ç‰‡ï¼ˆåªå–ç¬¬ä¸€é ï¼‰
        ext = file_ext.lower()
        if ext == 'pdf':
            image_paths = ImageProcessing.pdf_to_images(upload_path, app.config['UPLOAD_FOLDER'], dpi=300)
            if image_paths:
                image_path_for_ocr = image_paths[0]
            else:
                return jsonify({'error': 'PDF è½‰åœ–ç‰‡å¤±æ•—'}), 500
        else:
            image_path_for_ocr = upload_path

        # ====== Gemini OCR èˆ‡è³‡æ–™è™•ç† ======
        # ç”¢ç”ŸåŠ ä¸Šè¼”åŠ©ç·šçš„é è¦½åœ–ï¼ˆå¼·åŒ–å»èƒŒç´…ç·šç‰ˆæœ¬ï¼‰
        support_line_path = os.path.join('assets', 'watermark', 'table_line_redline_only.png')
        preview_images = ImageProcessing.overlay_support_line_on_pdf(
            image_path_for_ocr, TEMP_PREVIEW_FOLDER, support_line_path, dpi=300, alpha=1.0
        )
        if preview_images:
            overlay_preview_path = preview_images[0]
            overlay_preview_url = f"/temp_images/{os.path.basename(overlay_preview_path)}"
        else:
            overlay_preview_url = None

        # OCR è™•ç†ï¼ˆç„¡è«–æ˜¯å¦æœ‰é è¦½åœ–éƒ½åŸ·è¡Œï¼‰
        raw_data = ocr_processor.extract_insurance_data_with_gemini(image_path_for_ocr)
        # è³‡æ–™è™•ç†
        processed_data = data_processor.process_insurance_data(raw_data)

        # ====== èƒŒæ™¯ç”¢ç”Ÿè²¡ç”¢åˆ†ææ›¸ï¼ˆWord+PDFï¼‰ ======
        # åœ¨ä¸»æµç¨‹ç”¢ç”Ÿå”¯ä¸€æª”åï¼ˆåªç”¨æ™‚é–“æˆ³ï¼‰
        now = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
        word_filename = f'è²¡ç”¢åˆ†ææ›¸_{now}.docx'
        word_path = os.path.join('property_reports', word_filename)
        # å•Ÿå‹• thread æ™‚ï¼ŒæŠŠ word_path å‚³é€²å»
        def generate_property_report(processed_data, word_path):
            try:
                word_template_processor.fill_template(processed_data, output_path=word_path)
                # è¨»å†Šç”¢ç”Ÿçš„ Word æª”æ¡ˆï¼ˆç”¨æ–¼è‡ªå‹•æ¸…ç†ï¼‰
                add_session_file(word_path)
            except Exception as e:
                print(f'èƒŒæ™¯ç”¢ç”Ÿè²¡ç”¢åˆ†ææ›¸å¤±æ•—: {e}')
        if word_template_processor is not None:
            threading.Thread(target=generate_property_report, args=(processed_data, word_path)).start()
        # æ‘˜è¦
        data_summary = data_processor.get_data_summary(processed_data)
        
        # åˆ†æä¿æœŸè³‡è¨Šå’Œä¿éšªé¡å‹
        insurance_periods_info = {
            'compulsory_insurance_period': {
                'raw': raw_data.get('compulsory_insurance_period', ''),
                'processed': processed_data.get('compulsory_insurance_period', ''),
                'status': 'æœ‰è³‡æ–™' if processed_data.get('compulsory_insurance_period') and processed_data.get('compulsory_insurance_period') != 'ç„¡å¡«å¯«' else 'ç„¡å¡«å¯«'
            },
            'optional_insurance_period': {
                'raw': raw_data.get('optional_insurance_period', ''),
                'processed': processed_data.get('optional_insurance_period', ''),
                'status': 'æœ‰è³‡æ–™' if processed_data.get('optional_insurance_period') and processed_data.get('optional_insurance_period') != 'ç„¡å¡«å¯«' else 'ç„¡å¡«å¯«'
            }
        }
        
        # åˆ†æä¿éšªé¡å‹
        coverage_items = processed_data.get('coverage_items', [])
        insurance_types = {
            'has_compulsory': False,
            'has_optional': False,
            'compulsory_items': [],
            'optional_items': []
        }
        
        if isinstance(coverage_items, list):
            for item in coverage_items:
                if isinstance(item, dict):
                    insurance_type = item.get('ä¿éšªç¨®é¡', '')
                    if 'å¼·åˆ¶' in insurance_type:
                        insurance_types['has_compulsory'] = True
                        insurance_types['compulsory_items'].append(insurance_type)
                    elif any(keyword in insurance_type for keyword in ['è»Šé«”', 'ç«Šç›œ', 'ç¬¬ä¸‰äºº', 'è¶…é¡', 'é§•é§›äºº']):
                        insurance_types['has_optional'] = True
                        insurance_types['optional_items'].append(insurance_type)
        
        # ç”Ÿæˆæé†’è¨Šæ¯
        reminders = []
        
        # æ ¹æ“šä¿æœŸåˆ¤æ–·æ˜¯å¦æœ‰å¼·åˆ¶éšªå’Œä»»æ„éšª
        has_compulsory_period = insurance_periods_info['compulsory_insurance_period']['status'] == 'æœ‰è³‡æ–™'
        has_optional_period = insurance_periods_info['optional_insurance_period']['status'] == 'æœ‰è³‡æ–™'
        
        if not has_compulsory_period:
            reminders.append("æ²’æœ‰è¾¨è­˜åˆ°å¼·åˆ¶éšª")
        if not has_optional_period:
            reminders.append("æ²’æœ‰è¾¨è­˜åˆ°ä»»æ„éšª")
        
        # å¦‚æœæ²’æœ‰æé†’ï¼Œæ·»åŠ æˆåŠŸè¨Šæ¯
        if not reminders:
            reminders.append("æ‰€æœ‰ä¿éšªé …ç›®å’Œä¿æœŸéƒ½å·²æˆåŠŸè¾¨è­˜")
        
        # å¦‚æœç„¡æ³•ç”¢ç”Ÿé è¦½åœ–ï¼Œæ·»åŠ æé†’
        if not overlay_preview_path:
            reminders.append("âŒ ç„¡æ³•ç”¢ç”Ÿé è¦½åœ–ï¼Œè«‹æª¢æŸ¥æª”æ¡ˆæ ¼å¼")

        # è‡ªå‹•æ¸…ç†èˆŠè³‡æ–™ï¼ˆæ¯æ¬¡æ–°çš„è¦ä¿æ›¸è¾¨è­˜å®Œæˆå¾Œï¼‰
        # auto_cleanup_old_data()  # è¨»è§£è‡ªå‹•æ¸…ç†å‘¼å«
        
        response_data = {
            'original_filename': filename,
            'overlay_preview_image_url': overlay_preview_url,
            'original_preview_image_url': image_path_for_ocr if os.path.exists(image_path_for_ocr) else None,
            'extracted_data': processed_data,

            'data_summary': data_summary,
            'insurance_periods_info': insurance_periods_info,
            'insurance_types': insurance_types,
            'reminders': reminders,
            'total_fields': 20,
            'filled_fields': sum(1 for v in processed_data.values() if v and v != "ç„¡å¡«å¯«") if processed_data else 0,
            'extraction_rate': f"{sum(1 for v in processed_data.values() if v and v != 'ç„¡å¡«å¯«') / 20 * 100:.1f}%" if processed_data else "0.0%",
            'word_filename': word_filename,
            'pdf_filename': word_filename.replace('.docx', '.pdf')
        }

        return jsonify(response_data)
        
    except Exception as e:
        print(f"è™•ç†éŒ¯èª¤: {str(e)}")
        return jsonify({'error': f'è™•ç†å¤±æ•—: {str(e)}'}), 500

@app.route('/api/process', methods=['POST'])
def api_process():
    """APIç«¯é»ï¼šè™•ç†OCRå’ŒPDFç”Ÿæˆ"""
    try:
        data = request.get_json()
        
        if not data or 'image_path' not in data:
            return jsonify({'error': 'ç¼ºå°‘å¿…è¦åƒæ•¸'}), 400
        
        image_path = data['image_path']
        
        if not os.path.exists(image_path):
            return jsonify({'error': 'åœ–ç‰‡æª”æ¡ˆä¸å­˜åœ¨'}), 404
        
        # åŸ·è¡ŒOCRè™•ç†
        raw_data = ocr_processor.extract_insurance_data_with_gemini(image_path)
        processed_data = data_processor.process_insurance_data(raw_data)
        
        return jsonify({
            'success': True,
            'extracted_data': processed_data
        })
        
    except Exception as e:
        return jsonify({'error': f'APIè™•ç†å¤±æ•—: {str(e)}'}), 500

@app.route('/api/health')
def health_check():
    """å¥åº·æª¢æŸ¥ç«¯é»"""
    return jsonify({
        'status': 'healthy',
        'timestamp': datetime.now().isoformat(),
        'version': '1.0.0'
    })

@app.route('/api/generate-word', methods=['POST'])
def generate_word():
    """ç”Ÿæˆ Word æª”æ¡ˆ"""
    try:
        data = request.get_json()
        
        if not data or 'image_path' not in data:
            return jsonify({'error': 'ç¼ºå°‘å¿…è¦åƒæ•¸'}), 400
        
        image_path = data['image_path']
        
        if not os.path.exists(image_path):
            return jsonify({'error': 'åœ–ç‰‡æª”æ¡ˆä¸å­˜åœ¨'}), 404
        
        # å…ˆåŸ·è¡Œ OCR å–å¾—è³‡æ–™
        raw_data = ocr_processor.extract_insurance_data_with_gemini(image_path)
        if not raw_data:
            return jsonify({'error': 'OCR è¾¨è­˜å¤±æ•—'}), 500
        
        # è™•ç†è³‡æ–™
        processed_data = data_processor.process_insurance_data(raw_data)
        
        # æª¢æŸ¥ Word æ¨¡æ¿è™•ç†å™¨æ˜¯å¦å·²åˆå§‹åŒ–
        if word_template_processor is None:
            return jsonify({'error': 'Word æ¨¡æ¿è™•ç†å™¨æœªåˆå§‹åŒ–'}), 500
        
        # ä½¿ç”¨ Word æ¨¡æ¿è™•ç†å™¨ç”Ÿæˆæª”æ¡ˆ
        output_path = word_template_processor.fill_template(processed_data)
        
        # === æ–°å¢ï¼šè‡ªå‹•è½‰ PDF ===
        if output_path and output_path.endswith('.docx'):
            pdf_path = output_path.replace('.docx', '.pdf')
            if not os.path.exists(pdf_path):
                try:
                    import pythoncom
                    from docx2pdf import convert
                    pythoncom.CoInitialize()
                    convert(output_path, pdf_path)
                    pythoncom.CoUninitialize()
                except Exception as e:
                    print(f"[è‡ªå‹•è½‰ PDF å¤±æ•—] {e}")
        
        if output_path:
            filename = os.path.basename(output_path)
            return jsonify({
                'success': True,
                'word_filename': filename,
                'word_path': output_path,
                'download_url': f"/download/{filename}",
                'data_summary': data_processor.get_data_summary(processed_data)
            })
        else:
            return jsonify({'error': 'Word æª”æ¡ˆç”Ÿæˆå¤±æ•—'}), 500
        
    except Exception as e:
        return jsonify({'error': f'Word ç”Ÿæˆå¤±æ•—: {str(e)}'}), 500

@app.route('/api/generate-word-template', methods=['POST'])
def generate_word_template():
    """ä½¿ç”¨Wordæ¨¡æ¿ç”Ÿæˆè²¡ç”¢åˆ†ææ›¸"""
    try:
        data = request.get_json()
        
        if not data or 'ocr_data' not in data:
            return jsonify({'error': 'ç¼ºå°‘å¿…è¦åƒæ•¸'}), 400
        
        ocr_data = data['ocr_data']
        
        # æª¢æŸ¥ Word æ¨¡æ¿è™•ç†å™¨æ˜¯å¦å·²åˆå§‹åŒ–
        if word_template_processor is None:
            return jsonify({'error': 'Word æ¨¡æ¿è™•ç†å™¨æœªåˆå§‹åŒ–'}), 500
        
        # ä½¿ç”¨Wordæ¨¡æ¿è™•ç†å™¨
        output_path = word_template_processor.fill_template(ocr_data)
        
        # === æ–°å¢ï¼šè‡ªå‹•è½‰ PDF ===
        if output_path and output_path.endswith('.docx'):
            pdf_path = output_path.replace('.docx', '.pdf')
            if not os.path.exists(pdf_path):
                try:
                    import pythoncom
                    from docx2pdf import convert
                    pythoncom.CoInitialize()
                    convert(output_path, pdf_path)
                    pythoncom.CoUninitialize()
                except Exception as e:
                    print(f"[è‡ªå‹•è½‰ PDF å¤±æ•—] {e}")
        
        if output_path:
            filename = os.path.basename(output_path)
            return jsonify({
                'success': True,
                'word_filename': filename,
                'word_path': output_path,
                'download_url': f"/download/{filename}",
                'message': 'è²¡ç”¢åˆ†ææ›¸ç”ŸæˆæˆåŠŸ'
            })
        else:
            return jsonify({'error': 'Wordæ¨¡æ¿è™•ç†å¤±æ•—'}), 500
        
    except Exception as e:
        return jsonify({'error': f'Wordæ¨¡æ¿ç”Ÿæˆå¤±æ•—: {str(e)}'}), 500

@app.route('/api/generate-property-analysis', methods=['POST'])
def generate_property_analysis():
    """ç”Ÿæˆè²¡ç”¢åˆ†ææ›¸ï¼ˆæ•´åˆ information_integration åŠŸèƒ½ï¼‰"""
    try:
        data = request.get_json()
        
        if not data or 'extracted_data' not in data:
            return jsonify({'error': 'ç¼ºå°‘å¿…è¦åƒæ•¸'}), 400
        
        extracted_data = data['extracted_data']
        
        # æª¢æŸ¥ Word æ¨¡æ¿è™•ç†å™¨æ˜¯å¦å·²åˆå§‹åŒ–
        if word_template_processor is None:
            return jsonify({'error': 'Word æ¨¡æ¿è™•ç†å™¨æœªåˆå§‹åŒ–'}), 500
        
        # ä½¿ç”¨Wordæ¨¡æ¿è™•ç†å™¨ç”Ÿæˆè²¡ç”¢åˆ†ææ›¸
        output_path = word_template_processor.fill_template(extracted_data)
        
        # === æ–°å¢ï¼šè‡ªå‹•è½‰ PDF ===
        if output_path and output_path.endswith('.docx'):
            pdf_path = output_path.replace('.docx', '.pdf')
            if not os.path.exists(pdf_path):
                try:
                    import pythoncom
                    from docx2pdf import convert
                    pythoncom.CoInitialize()
                    convert(output_path, pdf_path)
                    pythoncom.CoUninitialize()
                except Exception as e:
                    print(f"[è‡ªå‹•è½‰ PDF å¤±æ•—] {e}")
        
        if output_path:
            filename = os.path.basename(output_path)
            response_data = {
                'success': True,
                'analysis_filename': filename,
                'analysis_path': output_path,
                'download_url': f"/download/{filename}",
                'message': 'è²¡ç”¢åˆ†ææ›¸ç”ŸæˆæˆåŠŸ'
            }
            
            return jsonify(response_data)
        else:
            return jsonify({'error': 'è²¡ç”¢åˆ†ææ›¸ç”Ÿæˆå¤±æ•—'}), 500
        
    except Exception as e:
        return jsonify({'error': f'è²¡ç”¢åˆ†ææ›¸ç”Ÿæˆå¤±æ•—: {str(e)}'}), 500

@app.route('/download/<filename>')
def download_file(filename):
    """ä¸‹è¼‰æª”æ¡ˆ"""
    try:
        return send_from_directory(app.config['OUTPUT_FOLDER'], filename, as_attachment=True)
    except Exception as e:
        return jsonify({'error': f'ä¸‹è¼‰å¤±æ•—: {str(e)}'}), 404

@app.route('/preview/<filename>')
def preview_file(filename):
    """é è¦½è²¡ç”¢åˆ†ææ›¸"""
    try:
        file_path = os.path.join(app.config['OUTPUT_FOLDER'], filename)
        if not os.path.exists(file_path):
            return jsonify({'error': 'æª”æ¡ˆä¸å­˜åœ¨'}), 404
        
        # å¦‚æœæ˜¯PDFæª”æ¡ˆï¼Œç›´æ¥è¿”å›
        if filename.lower().endswith('.pdf'):
            return send_from_directory(app.config['OUTPUT_FOLDER'], filename)
        
        # å¦‚æœæ˜¯Wordæª”æ¡ˆï¼Œè½‰æ›ç‚ºPDFå¾Œè¿”å›
        elif filename.lower().endswith('.docx'):
            pdf_filename = filename.replace('.docx', '.pdf')
            pdf_path = os.path.join(app.config['OUTPUT_FOLDER'], pdf_filename)
            
            if os.path.exists(pdf_path):
                return send_from_directory(app.config['OUTPUT_FOLDER'], pdf_filename)
            else:
                # å¦‚æœPDFä¸å­˜åœ¨ï¼Œå˜—è©¦è½‰æ›
                try:
                    import docx2pdf
                    docx2pdf.convert(file_path, pdf_path)
                    return send_from_directory(app.config['OUTPUT_FOLDER'], pdf_filename)
                except Exception as e:
                    return jsonify({'error': f'PDFè½‰æ›å¤±æ•—: {str(e)}'}), 500
        
        else:
            return jsonify({'error': 'ä¸æ”¯æ´çš„æª”æ¡ˆæ ¼å¼'}), 400
            
    except Exception as e:
        return jsonify({'error': f'é è¦½å¤±æ•—: {str(e)}'}), 500

@app.route('/api/analyze', methods=['POST'])
def analyze_image():
    """åˆ†æåœ–ç‰‡å“è³ªä¸¦æä¾›å„ªåŒ–å»ºè­°"""
    try:
        if 'file' not in request.files:
            return jsonify({'error': 'æ²’æœ‰é¸æ“‡æª”æ¡ˆ'}), 400
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({'error': 'æ²’æœ‰é¸æ“‡æª”æ¡ˆ'}), 400
        
        if not allowed_file(file.filename):
            return jsonify({'error': 'ä¸æ”¯æ´çš„æª”æ¡ˆæ ¼å¼'}), 400
        
        # ç”Ÿæˆæš«å­˜æª”æ¡ˆ
        filename = secure_filename(file.filename or 'unknown')
        file_ext = filename.rsplit('.', 1)[1].lower()
        temp_path = os.path.join(app.config['UPLOAD_FOLDER'], f"temp_{filename}.{file_ext}")
        
        file.save(temp_path)
        
        try:
            # åˆ†æåœ–ç‰‡å“è³ª
            quality_info = ocr_processor.analyze_image_quality(temp_path)
            
            # åŸ·è¡Œ Gemini OCR æ¸¬è©¦
            extracted_data = ocr_processor.extract_insurance_data_with_gemini(temp_path)
            extraction_stats = ocr_processor.get_extraction_summary(extracted_data)
            
            return jsonify({
                'quality_analysis': quality_info,
                'extracted_data': extracted_data,
                'extraction_stats': extraction_stats
            })
            
        finally:
            # cleanup_temp_files([temp_path])
            pass
        
    except Exception as e:
        return jsonify({'error': f'åˆ†æå¤±æ•—: {str(e)}'}), 500

@app.route('/temp_images/<path:filename>')
def temp_images_preview(filename):
    return send_from_directory(TEMP_PREVIEW_FOLDER, filename)

@app.route('/api/preview', methods=['POST'])
def api_preview():
    """æ”¯æ´è¦ä¿æ›¸ç–Šåˆè¼”åŠ©ç·šé è¦½èˆ‡è²¡ç”¢åˆ†ææ›¸ docx è½‰ PDF é è¦½"""
    try:
        data = request.get_json()
        print(f"[DEBUG] æ”¶åˆ° /api/preview è«‹æ±‚ï¼Œdata: {data}")
        # è²¡ç”¢åˆ†ææ›¸é è¦½
        if 'filename' in data:
            filename = data['filename']
            print(f"[DEBUG] filename: {filename}")
            file_path = os.path.join(app.config['OUTPUT_FOLDER'], filename)
            print(f"[DEBUG] file_path: {file_path}")
            print(f"[DEBUG] æª¢æŸ¥ docx æª”æ¡ˆæ˜¯å¦å­˜åœ¨: {os.path.exists(file_path)}")
            if not os.path.exists(file_path):
                print(f"[DEBUG] æª”æ¡ˆä¸å­˜åœ¨: {file_path}")
                return jsonify({'error': 'æª”æ¡ˆä¸å­˜åœ¨'}), 404
            # å¦‚æœæ˜¯ docx æª”æ¡ˆï¼Œå…ˆè½‰æˆ PDF
            if filename.lower().endswith('.docx'):
                print(f"[DEBUG] æª”æ¡ˆç‚º docxï¼Œæº–å‚™é€²è¡Œ PDF è½‰æª”æµç¨‹")
                pdf_filename = filename.replace('.docx', '.pdf')
                pdf_path = os.path.join(app.config['OUTPUT_FOLDER'], pdf_filename)
                print(f"[DEBUG] é æœŸ PDF è·¯å¾‘: {pdf_path}")
                # å¦‚æœ PDF ä¸å­˜åœ¨ï¼Œå‰‡è½‰æ›
                if not os.path.exists(pdf_path):
                    print(f"[DEBUG] PDF ä¸å­˜åœ¨ï¼Œé–‹å§‹è½‰æª”...")
                    try:
                        import pythoncom
                        from docx2pdf import convert
                        pythoncom.CoInitialize()
                        print(f"ğŸ”„ æº–å‚™å°‡ {file_path} è½‰æˆ PDFï¼ˆdocx2pdfï¼‰...")
                        convert(file_path, pdf_path)
                        print(f"âœ… PDF ç”¢ç”ŸæˆåŠŸ: {pdf_path}")
                    except Exception as e:
                        print(f"âŒ PDF è½‰æ›å¤±æ•—: {e}")
                        return jsonify({'error': f'PDF è½‰æ›å¤±æ•—: {e}'}), 500
                    finally:
                        try:
                            pythoncom.CoUninitialize()
                        except Exception:
                            pass
                else:
                    print(f"[DEBUG] PDF å·²å­˜åœ¨: {pdf_path}")
            # ç”¢ç”Ÿ PNG é è¦½
            try:
                import fitz
                print(f"[DEBUG] é–‹å§‹ç”¢ç”Ÿ PNG é è¦½: {pdf_path}")
                doc = fitz.open(pdf_path)
                page = doc.load_page(0)
                pix = page.get_pixmap(dpi=150)
                os.makedirs('temp_images', exist_ok=True)
                preview_path = f'temp_images/preview_{os.path.splitext(filename)[0]}.png'
                pix.save(preview_path)
                print(f"âœ… é è¦½åœ–ç‰‡ç”¢ç”ŸæˆåŠŸ: {preview_path}")
                return jsonify({'preview_url': f'/{preview_path}'})
            except Exception as e:
                print(f"âŒ é è¦½åœ–ç‰‡ç”¢ç”Ÿå¤±æ•—: {e}")
                return jsonify({'error': f'é è¦½åœ–ç‰‡ç”¢ç”Ÿå¤±æ•—: {e}'}), 500
        # è¦ä¿æ›¸ç–Šåˆè¼”åŠ©ç·šé è¦½
        image_path = data.get('image_path')
        if not image_path or not os.path.exists(image_path):
            return jsonify({'error': 'åœ–ç‰‡æª”æ¡ˆä¸å­˜åœ¨'}), 404
        preview_path = os.path.join(TEMP_PREVIEW_FOLDER, f'{filename}_preview.png')
        support_line_path = os.path.join('assets', 'watermark', 'table_line_redline_only.png')
        ImageProcessing.overlay_support_line_on_image(
            image_path, support_line_path, preview_path,
            orig_size=(2481, 3508), crop_box=(81, 1157, 1797, 747), alpha=1.0
        )
        overlay_preview_url = f"/temp_images/{filename}_preview.png"
        return jsonify({'preview_url': overlay_preview_url})
    except Exception as e:
        print(f"âŒ /api/preview ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e}")
        return jsonify({'error': f'é è¦½ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e}'}), 500

@app.route('/api/test-insurance-periods', methods=['POST'])
def test_insurance_periods():
    """æ¸¬è©¦ä¿æœŸæ¬„ä½è™•ç†åŠŸèƒ½"""
    try:
        if 'file' not in request.files:
            return jsonify({'error': 'æ²’æœ‰é¸æ“‡æª”æ¡ˆ'}), 400
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({'error': 'æ²’æœ‰é¸æ“‡æª”æ¡ˆ'}), 400
        
        if not allowed_file(file.filename):
            return jsonify({'error': 'ä¸æ”¯æ´çš„æª”æ¡ˆæ ¼å¼'}), 400
        
        # ç”Ÿæˆå”¯ä¸€æª”æ¡ˆå
        filename = secure_filename(file.filename or 'unknown')
        file_ext = filename.rsplit('.', 1)[1].lower()
        upload_path = os.path.join(app.config['UPLOAD_FOLDER'], f"{filename}.{file_ext}")
        
        # ä¿å­˜ä¸Šå‚³çš„æª”æ¡ˆ
        file.save(upload_path)

        # å¦‚æœæ˜¯ PDFï¼Œå…ˆè½‰æˆåœ–ç‰‡ï¼ˆåªå–ç¬¬ä¸€é ï¼‰
        ext = file_ext.lower()
        if ext == 'pdf':
            image_paths = ImageProcessing.pdf_to_images(upload_path, app.config['UPLOAD_FOLDER'], dpi=300)
            if image_paths:
                image_path_for_ocr = image_paths[0]
            else:
                return jsonify({'error': 'PDF è½‰åœ–ç‰‡å¤±æ•—'}), 500
        else:
            image_path_for_ocr = upload_path

        # åŸ·è¡Œ Gemini OCR
        print("ğŸ”„ åŸ·è¡Œ Gemini OCR...")
        raw_data = ocr_processor.extract_insurance_data_with_gemini(image_path_for_ocr)
        
        if not raw_data:
            return jsonify({'error': 'OCR è¾¨è­˜å¤±æ•—'}), 500
        
        # è³‡æ–™è™•ç†
        print("ğŸ”„ è™•ç†è³‡æ–™...")
        processed_data = data_processor.process_insurance_data(raw_data)
        
        # æº–å‚™å›æ‡‰è³‡æ–™
        response_data = {
            'original_filename': filename,
            'raw_ocr_data': raw_data,
            'processed_data': processed_data,
            'insurance_periods_info': {
                'compulsory_insurance_period': {
                    'raw': raw_data.get('compulsory_insurance_period', ''),
                    'processed': processed_data.get('compulsory_insurance_period', ''),
                    'status': 'æœ‰è³‡æ–™' if processed_data.get('compulsory_insurance_period') and processed_data.get('compulsory_insurance_period') != 'ç„¡å¡«å¯«' else 'ç„¡å¡«å¯«'
                },
                'optional_insurance_period': {
                    'raw': raw_data.get('optional_insurance_period', ''),
                    'processed': processed_data.get('optional_insurance_period', ''),
                    'status': 'æœ‰è³‡æ–™' if processed_data.get('optional_insurance_period') and processed_data.get('optional_insurance_period') != 'ç„¡å¡«å¯«' else 'ç„¡å¡«å¯«'
                }
            },
            'total_fields': 20,
            'filled_fields': sum(1 for v in processed_data.values() if v and v != "ç„¡å¡«å¯«"),
            'extraction_rate': f"{sum(1 for v in processed_data.values() if v and v != 'ç„¡å¡«å¯«') / 20 * 100:.1f}%"
        }

        return jsonify(response_data)
        
    except Exception as e:
        print(f"æ¸¬è©¦ä¿æœŸè™•ç†éŒ¯èª¤: {str(e)}")
        return jsonify({'error': f'æ¸¬è©¦å¤±æ•—: {str(e)}'}), 500

@app.errorhandler(413)
def too_large(e):
    """æª”æ¡ˆéå¤§éŒ¯èª¤è™•ç†"""
    return jsonify({'error': 'æª”æ¡ˆå¤§å°è¶…éé™åˆ¶ (æœ€å¤§16MB)'}), 413

@app.errorhandler(404)
def not_found(e):
    """404éŒ¯èª¤è™•ç†"""
    return jsonify({'error': 'é é¢ä¸å­˜åœ¨'}), 404

@app.route('/api/cleanup', methods=['POST'])
def cleanup_data():
    """æ¸…ç†èˆŠè³‡æ–™"""
    try:
        data = request.get_json() or {}
        cleanup_type = data.get('type', 'all')  # all, uploads, ocr_results, property_reports
        
        cleaned_files = []
        total_size_freed = 0
        
        if cleanup_type in ['all', 'uploads']:
            # æ¸…ç†uploadsè³‡æ–™å¤¾ï¼ˆä¿ç•™æœ€è¿‘5å€‹æª”æ¡ˆï¼‰
            # uploads_cleaned = cleanup_old_files(app.config['UPLOAD_FOLDER'], keep_count=5)
            # cleaned_files.extend(uploads_cleaned['files'])
            # total_size_freed += uploads_cleaned['size_freed']
            pass
        
        if cleanup_type in ['all', 'ocr_results']:
            # æ¸…ç†ocr_resultsè³‡æ–™å¤¾ï¼ˆä¿ç•™æœ€è¿‘10å€‹æª”æ¡ˆï¼‰
            # ocr_cleaned = cleanup_old_files('ocr_results', keep_count=10)
            # cleaned_files.extend(ocr_cleaned['files'])
            # total_size_freed += ocr_cleaned['size_freed']
            pass
        
        if cleanup_type in ['all', 'property_reports']:
            # æ¸…ç†property_reportsè³‡æ–™å¤¾ï¼ˆä¿ç•™æœ€è¿‘5å€‹æª”æ¡ˆï¼‰
            # reports_cleaned = cleanup_old_files(app.config['OUTPUT_FOLDER'], keep_count=5)
            # cleaned_files.extend(reports_cleaned['files'])
            # total_size_freed += reports_cleaned['size_freed']
            pass
        
        # æ¸…ç†temp_imagesè³‡æ–™å¤¾
        # temp_cleaned = cleanup_temp_files_in_folder('temp_images')
        # cleaned_files.extend(temp_cleaned['files'])
        # total_size_freed += temp_cleaned['size_freed']
        
        return jsonify({
            'success': True,
            'cleaned_files': cleaned_files,
            'total_files_cleaned': len(cleaned_files),
            'total_size_freed_mb': round(total_size_freed / (1024 * 1024), 2),
            'message': f'æˆåŠŸæ¸…ç† {len(cleaned_files)} å€‹æª”æ¡ˆï¼Œé‡‹æ”¾ {round(total_size_freed / (1024 * 1024), 2)} MB ç©ºé–“'
        })
        
    except Exception as e:
        return jsonify({'error': f'æ¸…ç†å¤±æ•—: {str(e)}'}), 500

@app.route('/api/cleanup/status', methods=['GET'])
def cleanup_status():
    """å–å¾—è‡ªå‹•æ¸…ç†ç‹€æ…‹"""
    try:
        manager = get_cleanup_manager()
        status = manager.get_status()
        
        return jsonify({
            'success': True,
            'status': status,
            'message': 'è‡ªå‹•æ¸…ç†ç‹€æ…‹æŸ¥è©¢æˆåŠŸ'
        })
        
    except Exception as e:
        return jsonify({'error': f'æŸ¥è©¢ç‹€æ…‹å¤±æ•—: {str(e)}'}), 500

def cleanup_old_files(folder_path: str, keep_count: int = 5) -> dict:
    """æ¸…ç†èˆŠæª”æ¡ˆï¼Œä¿ç•™æŒ‡å®šæ•¸é‡çš„æœ€æ–°æª”æ¡ˆ"""
    try:
        if not os.path.exists(folder_path):
            return {'files': [], 'size_freed': 0}
        
        # ç²å–æ‰€æœ‰æª”æ¡ˆåŠå…¶ä¿®æ”¹æ™‚é–“
        files = []
        for filename in os.listdir(folder_path):
            file_path = os.path.join(folder_path, filename)
            if os.path.isfile(file_path):
                mtime = os.path.getmtime(file_path)
                size = os.path.getsize(file_path)
                files.append((file_path, filename, mtime, size))
        
        # æŒ‰ä¿®æ”¹æ™‚é–“æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        files.sort(key=lambda x: x[2], reverse=True)
        
        # ä¿ç•™æœ€æ–°çš„æª”æ¡ˆï¼Œåˆªé™¤å…¶é¤˜çš„
        files_to_delete = files[keep_count:]
        deleted_files = []
        total_size_freed = 0
        
        for file_path, filename, mtime, size in files_to_delete:
            try:
                os.remove(file_path)
                deleted_files.append(filename)
                total_size_freed += size
            except Exception as e:
                print(f"åˆªé™¤æª”æ¡ˆå¤±æ•— {filename}: {str(e)}")
        
        return {
            'files': deleted_files,
            'size_freed': total_size_freed
        }
        
    except Exception as e:
        print(f"æ¸…ç†è³‡æ–™å¤¾å¤±æ•— {folder_path}: {str(e)}")
        return {'files': [], 'size_freed': 0}

def auto_cleanup_old_data():
    """è‡ªå‹•æ¸…ç†èˆŠè³‡æ–™ï¼ˆæ¯æ¬¡æ–°çš„è¦ä¿æ›¸è¾¨è­˜å®Œæˆå¾ŒåŸ·è¡Œï¼‰"""
    try:
        print("ğŸ§¹ è‡ªå‹•æ¸…ç†èˆŠè³‡æ–™...")
        
        cleaned_files = []
        total_size_freed = 0
        
        # æ¸…ç†uploadsè³‡æ–™å¤¾ï¼ˆä¿ç•™æœ€è¿‘2å€‹æª”æ¡ˆï¼Œæ¸…ç†ä¹‹å‰çš„ï¼‰
        # uploads_cleaned = cleanup_old_files(app.config['UPLOAD_FOLDER'], keep_count=2)
        # cleaned_files.extend(uploads_cleaned['files'])
        # total_size_freed += uploads_cleaned['size_freed']
        
        # æ¸…ç†ocr_resultsè³‡æ–™å¤¾ï¼ˆä¿ç•™æœ€è¿‘3å€‹æª”æ¡ˆï¼Œæ¸…ç†ä¹‹å‰çš„ï¼‰
        # ocr_cleaned = cleanup_old_files('ocr_results', keep_count=3)
        # cleaned_files.extend(ocr_cleaned['files'])
        # total_size_freed += ocr_cleaned['size_freed']
        
        # æ¸…ç†property_reportsè³‡æ–™å¤¾ï¼ˆä¿ç•™æœ€è¿‘2å€‹æª”æ¡ˆï¼Œæ¸…ç†ä¹‹å‰çš„ï¼‰
        # reports_cleaned = cleanup_old_files(app.config['OUTPUT_FOLDER'], keep_count=2)
        # cleaned_files.extend(reports_cleaned['files'])
        # total_size_freed += reports_cleaned['size_freed']
        
        # ä¸æ¸…ç†temp_imagesè³‡æ–™å¤¾ï¼Œä¿ç•™ç•¶å‰é è¦½åœ–ç‰‡ä¾›å‰ç«¯ä½¿ç”¨
        # temp_cleaned = cleanup_temp_files_in_folder('temp_images')
        # cleaned_files.extend(temp_cleaned['files'])
        # total_size_freed += temp_cleaned['size_freed']
        
        if cleaned_files:
            print(f"âœ… è‡ªå‹•æ¸…ç†å®Œæˆï¼šåˆªé™¤ {len(cleaned_files)} å€‹æª”æ¡ˆï¼Œé‡‹æ”¾ {round(total_size_freed / (1024 * 1024), 2)} MB ç©ºé–“")
        else:
            print("âœ… ç„¡éœ€æ¸…ç†çš„æª”æ¡ˆ")
            
    except Exception as e:
        print(f"âŒ è‡ªå‹•æ¸…ç†å¤±æ•—: {str(e)}")

def cleanup_temp_files_in_folder(folder_path: str) -> dict:
    """æ¸…ç†æš«å­˜æª”æ¡ˆè³‡æ–™å¤¾"""
    try:
        if not os.path.exists(folder_path):
            return {'files': [], 'size_freed': 0}
        
        deleted_files = []
        total_size_freed = 0
        
        for filename in os.listdir(folder_path):
            file_path = os.path.join(folder_path, filename)
            if os.path.isfile(file_path):
                try:
                    size = os.path.getsize(file_path)
                    os.remove(file_path)
                    deleted_files.append(filename)
                    total_size_freed += size
                except Exception as e:
                    print(f"åˆªé™¤æš«å­˜æª”æ¡ˆå¤±æ•— {filename}: {str(e)}")
        
        return {
            'files': deleted_files,
            'size_freed': total_size_freed
        }
        
    except Exception as e:
        print(f"æ¸…ç†æš«å­˜è³‡æ–™å¤¾å¤±æ•— {folder_path}: {str(e)}")
        return {'files': [], 'size_freed': 0}

@app.errorhandler(500)
def internal_error(e):
    """500éŒ¯èª¤è™•ç†"""
    return jsonify({'error': 'ä¼ºæœå™¨å…§éƒ¨éŒ¯èª¤'}), 500

if __name__ == '__main__':
    print("å•Ÿå‹•ä¿å–®è¾¨è­˜ç³»çµ±...")
    print("è«‹è¨ªå•: http://localhost:5000")
    
    try:
        # åœ¨ Windows ä¸Šä½¿ç”¨ threaded=True å’Œ use_reloader=False ä¾†é¿å…é€šè¨Šç«¯éŒ¯èª¤
        app.run(
            debug=True, 
            host='0.0.0.0', 
            port=5000,
            threaded=True,
            use_reloader=False  # é—œé–‰è‡ªå‹•é‡è¼‰ä»¥é¿å…é€šè¨Šç«¯éŒ¯èª¤
        )
    except KeyboardInterrupt:
        print("\næ­£åœ¨é—œé–‰ç³»çµ±...")
    except OSError as e:
        if "å˜—è©¦æ“ä½œçš„å°è±¡ä¸æ˜¯é€šè¨Šç«¯" in str(e):
            print("âš ï¸  æª¢æ¸¬åˆ°é€šè¨Šç«¯éŒ¯èª¤ï¼Œé€™é€šå¸¸æ˜¯æ­£å¸¸çš„é—œé–‰éç¨‹")
        else:
            print(f"âŒ ç³»çµ±éŒ¯èª¤: {str(e)}")
    finally:
        # ç¨‹å¼çµæŸæ™‚åœæ­¢è‡ªå‹•æ¸…ç†
        try:
            stop_auto_cleanup()
            print("âœ… è‡ªå‹•æ¸…ç†ç®¡ç†å™¨å·²åœæ­¢")
        except Exception as e:
            print(f"âŒ åœæ­¢è‡ªå‹•æ¸…ç†ç®¡ç†å™¨å¤±æ•—: {str(e)}") 