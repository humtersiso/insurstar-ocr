#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Word å¡«å¯«ç³»çµ±
æ•´åˆ Gemini OCR è¾¨è­˜çµæœèˆ‡ Word æ¨¡æ¿ç”Ÿæˆ
"""

import os
import json
import uuid
from datetime import datetime
from typing import Dict, List, Any, Optional

from gemini_ocr_processor import GeminiOCRProcessor
from data_processor import DataProcessor
from word_template_generator import WordTemplateGenerator

class WordFiller:
    """Word å¡«å¯«ç³»çµ±"""
    
    def __init__(self):
        """åˆå§‹åŒ– Word å¡«å¯«ç³»çµ±"""
        self.ocr_processor = GeminiOCRProcessor()
        self.data_processor = DataProcessor()
        self.word_generator = WordTemplateGenerator()
        
        # å»ºç«‹è¼¸å‡ºç›®éŒ„
        self.output_dir = 'outputs'
        os.makedirs(self.output_dir, exist_ok=True)
    
    def process_insurance_document(self, image_path: str) -> Dict:
        """
        è™•ç†ä¿éšªæ–‡ä»¶ï¼šOCR è¾¨è­˜ + Word ç”Ÿæˆ
        
        Args:
            image_path: åœ–ç‰‡è·¯å¾‘
            
        Returns:
            è™•ç†çµæœå­—å…¸
        """
        try:
            print(f"ğŸ” é–‹å§‹è™•ç†æ–‡ä»¶: {image_path}")
            
            # 1. OCR è¾¨è­˜
            print("ğŸ“ åŸ·è¡Œ OCR è¾¨è­˜...")
            raw_data = self.ocr_processor.extract_insurance_data_with_gemini(image_path)
            
            if not raw_data:
                return {
                    'success': False,
                    'error': 'OCR è¾¨è­˜å¤±æ•—ï¼Œç„¡æ³•æå–è³‡æ–™'
                }
            
            print("âœ… OCR è¾¨è­˜å®Œæˆ")
            print(f"ğŸ“Š åŸå§‹è³‡æ–™: {json.dumps(raw_data, ensure_ascii=False, indent=2)}")
            
            # 2. è³‡æ–™è™•ç†
            print("ğŸ”„ è™•ç†è³‡æ–™...")
            processed_data = self.data_processor.process_insurance_data(raw_data)
            validation_result = self.data_processor.validate_processed_data(processed_data)
            
            print("âœ… è³‡æ–™è™•ç†å®Œæˆ")
            print(f"ğŸ“Š è™•ç†å¾Œè³‡æ–™: {json.dumps(processed_data, ensure_ascii=False, indent=2)}")
            
            # 3. ç”Ÿæˆ Word æª”æ¡ˆ
            print("ğŸ“„ ç”Ÿæˆ Word æª”æ¡ˆ...")
            file_id = str(uuid.uuid4())
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            word_filename = f"property_analysis_{file_id}_{timestamp}.docx"
            word_path = os.path.join(self.output_dir, word_filename)
            
            word_result = self.word_generator.create_property_analysis_docx(processed_data, word_path)
            
            if not word_result:
                return {
                    'success': False,
                    'error': 'Word æª”æ¡ˆç”Ÿæˆå¤±æ•—'
                }
            
            print("âœ… Word æª”æ¡ˆç”Ÿæˆå®Œæˆ")
            
            # 4. æº–å‚™å›æ‡‰è³‡æ–™
            result = {
                'success': True,
                'file_id': file_id,
                'original_image': image_path,
                'word_path': word_path,
                'word_filename': word_filename,
                'raw_data': raw_data,
                'processed_data': processed_data,
                'validation_result': validation_result,
                'data_summary': self.data_processor.get_data_summary(processed_data),
                'processing_time': datetime.now().isoformat(),
                'download_url': f"/download/{word_filename}"
            }
            
            print("ğŸ‰ æ–‡ä»¶è™•ç†å®Œæˆï¼")
            return result
            
        except Exception as e:
            print(f"âŒ è™•ç†å¤±æ•—: {str(e)}")
            return {
                'success': False,
                'error': f'è™•ç†å¤±æ•—: {str(e)}'
            }
    
    def batch_process_documents(self, image_paths: List[str]) -> List[Dict]:
        """
        æ‰¹æ¬¡è™•ç†å¤šå€‹æ–‡ä»¶
        
        Args:
            image_paths: åœ–ç‰‡è·¯å¾‘åˆ—è¡¨
            
        Returns:
            è™•ç†çµæœåˆ—è¡¨
        """
        results = []
        
        print(f"ğŸš€ é–‹å§‹æ‰¹æ¬¡è™•ç† {len(image_paths)} å€‹æ–‡ä»¶")
        
        for i, image_path in enumerate(image_paths, 1):
            print(f"\nğŸ“„ è™•ç†ç¬¬ {i}/{len(image_paths)} å€‹æ–‡ä»¶: {image_path}")
            
            result = self.process_insurance_document(image_path)
            results.append(result)
            
            if result['success']:
                print(f"âœ… ç¬¬ {i} å€‹æ–‡ä»¶è™•ç†æˆåŠŸ")
            else:
                print(f"âŒ ç¬¬ {i} å€‹æ–‡ä»¶è™•ç†å¤±æ•—: {result.get('error', 'æœªçŸ¥éŒ¯èª¤')}")
        
        print(f"\nğŸ‰ æ‰¹æ¬¡è™•ç†å®Œæˆï¼æˆåŠŸ: {sum(1 for r in results if r['success'])}/{len(results)}")
        return results
    
    def get_processing_summary(self, results: List[Dict]) -> Dict:
        """
        å–å¾—è™•ç†æ‘˜è¦
        
        Args:
            results: è™•ç†çµæœåˆ—è¡¨
            
        Returns:
            è™•ç†æ‘˜è¦
        """
        total = len(results)
        successful = sum(1 for r in results if r['success'])
        failed = total - successful
        
        # çµ±è¨ˆæ¬„ä½è¾¨è­˜ç‡
        total_fields = 0
        filled_fields = 0
        
        for result in results:
            if result['success']:
                summary = result.get('data_summary', {})
                total_fields += summary.get('total_fields', 0)
                filled_fields += summary.get('filled_fields', 0)
        
        avg_extraction_rate = (filled_fields / total_fields * 100) if total_fields > 0 else 0
        
        return {
            'total_documents': total,
            'successful_documents': successful,
            'failed_documents': failed,
            'success_rate': f"{successful / total * 100:.1f}%" if total > 0 else "0%",
            'average_extraction_rate': f"{avg_extraction_rate:.1f}%",
            'generated_files': [r['word_filename'] for r in results if r['success']],
            'errors': [r['error'] for r in results if not r['success']]
        }

def main():
    """æ¸¬è©¦å‡½æ•¸"""
    print("ğŸ“„ Word å¡«å¯«ç³»çµ±æ¸¬è©¦")
    print("=" * 50)
    
    # åˆå§‹åŒ–ç³»çµ±
    word_filler = WordFiller()
    
    # æª¢æŸ¥æ¸¬è©¦åœ–ç‰‡
    test_images = []
    for ext in ['jpg', 'jpeg', 'png', 'bmp', 'tiff']:
        for file in os.listdir('converted_images'):
            if file.lower().endswith(f'.{ext}'):
                test_images.append(os.path.join('converted_images', file))
    
    if not test_images:
        print("âŒ æ²’æœ‰æ‰¾åˆ°æ¸¬è©¦åœ–ç‰‡")
        return
    
    # é¸æ“‡ç¬¬ä¸€å€‹åœ–ç‰‡é€²è¡Œæ¸¬è©¦
    test_image = test_images[0]
    print(f"ğŸ“¸ æ¸¬è©¦åœ–ç‰‡: {test_image}")
    
    # è™•ç†æ–‡ä»¶
    result = word_filler.process_insurance_document(test_image)
    
    if result['success']:
        print(f"âœ… è™•ç†æˆåŠŸï¼")
        print(f"ğŸ“„ Word æª”æ¡ˆ: {result['word_filename']}")
        print(f"ğŸ“Š è³‡æ–™æ‘˜è¦: {result['data_summary']}")
        print(f"ğŸ” é©—è­‰çµæœ: {result['validation_result']}")
        print(f"ğŸ“ è«‹ç”¨ Microsoft Word æˆ– LibreOffice é–‹å•Ÿæª¢æŸ¥å…§å®¹")
    else:
        print(f"âŒ è™•ç†å¤±æ•—: {result['error']}")

if __name__ == "__main__":
    main() 